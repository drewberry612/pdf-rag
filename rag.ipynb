{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef404c07-347a-45f2-8cfe-7cf2815e6661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def print_current_time():\n",
    "    current_time = datetime.now()\n",
    "    formatted_time = current_time.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time:\", formatted_time)\n",
    "\n",
    "print_current_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052b131-b334-4876-8617-cf7598b29d97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f73059-8809-4119-be55-2bc5641d1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from IPython.display import display as Markdown\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fe2e8-19f7-4130-9d9c-d47b132ab7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessary if no protobuf compatibility issues\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c5753-bbd1-47ef-a68a-ebab72ea494f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1912e0-9e50-4457-8482-77c7019dad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_current_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cf1ce-f94b-4fd2-a392-9d60c69475ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_path = \"test-doc.pdf\"\n",
    "\n",
    "if local_path:\n",
    "  loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "  data = loader.load()\n",
    "else:\n",
    "  print(\"Upload a PDF file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38119195-9c91-4e58-aa46-8a74244032af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(Markdown(data[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faacc1-be29-4d52-a46e-94f5b5b8e728",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f5ab59-3fd7-4cf7-8dd9-440f7dea6719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590e248-6796-4d96-9f8d-d86a072053cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "access_token = \"insert_your_access_token_here\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b5866-87ad-4430-a027-e8aaf7cfc815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LlamaEmbeddings(Embeddings):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states\n",
    "            \n",
    "            last_hidden_state = hidden_states[-1]\n",
    "            embeddings = last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "            embeddings = embeddings.tolist()\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return self.embed_documents([query])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf146bf4-6cec-4cc1-99a9-338eba877c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=LlamaEmbeddings(model, tokenizer),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eadf50-2f3d-4420-8858-94e9c1682ffa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f9e48-befd-478c-8683-94a0f1a31695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id=model_name, huggingfacehub_api_token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e949b-7ca9-4f5d-9377-1b05ce07694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c3cd0-3d77-4b6e-a2aa-677f8c0121dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ddd4a-0e47-4935-8ed5-d471626134f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b66c7b-faca-423e-ba70-904670160bb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc118c7-08e9-4b8e-af0c-0689e2c2f8bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150323a8-fcd3-441c-b6ab-7882364356ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_current_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a16e6-d10d-45de-af3d-e81bc9049788",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What are the 5 pillars of global cooperation? Include an explanation of each pillar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9946b-ce62-444d-8f55-d2b9461d1089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_current_time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
